{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robertzengcn/ai-finetuing/blob/master/small_language_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJrCHDQoNCuW",
        "outputId": "f2aa00b3-ff2c-4f1c-96a4-cc733f49941c"
      },
      "outputs": [],
      "source": [
        "#%pip install torch torchtext transformers sentencepiece pandas tqdm datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_DQG9OdLNjkf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset,DatasetDict,Dataset\n",
        "import pandas as pd\n",
        "import ast\n",
        "import datasets\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "z6riSp3XTBpW",
        "outputId": "1bb5409f-9c15-43fc-dc39-611c8abcf26d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (3.6.0)\n",
            "Requirement already satisfied: huggingface_hub in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (0.33.2)\n",
            "Requirement already satisfied: fsspec in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (2025.3.0)\n",
            "Collecting fsspec\n",
            "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: filelock in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from datasets) (2.3.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from datasets) (20.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from datasets) (2.3.0)\n",
            "Requirement already satisfied: requests>=2.32.2 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: packaging in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from huggingface_hub) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from huggingface_hub) (1.1.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.0 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -U datasets huggingface_hub fsspec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "9ZaICr5uRbGI",
        "outputId": "a9d4adfc-732e-493e-abf5-9826c24ce885"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        }
      ],
      "source": [
        "data_sample=load_dataset(\"QuyenAnhDE/Diseases_Symptoms\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['Code', 'Name', 'Symptoms', 'Treatments'],\n",
              "        num_rows: 400\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "updatad_data=[{'Name':item['Name'],'Symtoms':item['Symptoms']} for item in data_sample['train']]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "df=pd.DataFrame(updatad_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Symtoms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Panic disorder</td>\n",
              "      <td>Palpitations, Sweating, Trembling, Shortness o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Vocal cord polyp</td>\n",
              "      <td>Hoarseness, Vocal Changes, Vocal Fatigue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Turner syndrome</td>\n",
              "      <td>Short stature, Gonadal dysgenesis, Webbed neck...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cryptorchidism</td>\n",
              "      <td>Absence or undescended testicle(s), empty scro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ethylene glycol poisoning-1</td>\n",
              "      <td>Nausea, vomiting, abdominal pain, General mala...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Name  \\\n",
              "0               Panic disorder   \n",
              "1             Vocal cord polyp   \n",
              "2              Turner syndrome   \n",
              "3               Cryptorchidism   \n",
              "4  Ethylene glycol poisoning-1   \n",
              "\n",
              "                                             Symtoms  \n",
              "0  Palpitations, Sweating, Trembling, Shortness o...  \n",
              "1           Hoarseness, Vocal Changes, Vocal Fatigue  \n",
              "2  Short stature, Gonadal dysgenesis, Webbed neck...  \n",
              "3  Absence or undescended testicle(s), empty scro...  \n",
              "4  Nausea, vomiting, abdominal pain, General mala...  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "#just extract the symptoms\n",
        "df['Symtoms']=df['Symtoms'].apply(lambda x: ', '.join(x.split(',')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      Palpitations,  Sweating,  Trembling,  Shortnes...\n",
              "1             Hoarseness,  Vocal Changes,  Vocal Fatigue\n",
              "2      Short stature,  Gonadal dysgenesis,  Webbed ne...\n",
              "3      Absence or undescended testicle(s),  empty scr...\n",
              "4      Nausea,  vomiting,  abdominal pain,  General m...\n",
              "                             ...                        \n",
              "395    Severe abdominal or back pain,  blood in urine...\n",
              "396    Fragile bones,  loss of height over time,  bac...\n",
              "397    Joint pain,  stiffness,  swelling,  fatigue,  ...\n",
              "398    Frequent urination,  Increased thirst,  Weight...\n",
              "399    Fatigue,  Increased hunger,  Slow healing of w...\n",
              "Name: Symtoms, Length: 400, dtype: object"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Symtoms']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (4.53.0)\n",
            "Requirement already satisfied: filelock in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from transformers) (0.33.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from transformers) (2.3.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from requests->transformers) (2025.6.15)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader,Dataset,random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    try:\n",
        "        device = torch.device(\"mps\")    \n",
        "    except Exception:\n",
        "        device = torch.device(\"cpu\")   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer=GPT2Tokenizer.from_pretrained(\"distilgpt2\")\n",
        "model=GPT2LMHeadModel.from_pretrained(\"distilgpt2\").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-5): 6 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D(nf=2304, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=768)\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D(nf=3072, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=3072)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Symtoms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>400</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>392</td>\n",
              "      <td>395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Sciatica</td>\n",
              "      <td>Swelling,  pain,  dry mouth,  bad taste</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Name                                  Symtoms\n",
              "count        400                                      400\n",
              "unique       392                                      395\n",
              "top     Sciatica  Swelling,  pain,  dry mouth,  bad taste\n",
              "freq           3                                        3"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset Prep\n",
        "class LanguageDataset(Dataset):\n",
        "    def __init__(self,df,tokenizer):\n",
        "        self.labels=df.columns\n",
        "        self.data=df.to_dict(orient='records')\n",
        "        self.tokenizer=tokenizer\n",
        "        x=self.fittest_max_length(df)\n",
        "        self.nax_length=x\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    def __getitem__(self, idx):\n",
        "        x=self.data[idx][self.labels[0]]\n",
        "        y=self.data[idx][self.labels[1]]\n",
        "        text=f\"{x} | {y}\" \n",
        "        tokens=self.tokenizer.encode_plus(text,return_tensors='pt',max_length=128,padding='max_length')\n",
        "        return tokens\n",
        "    def fittest_max_length(self,df):\n",
        "        max_length=max(len(max(df[self.labels[0]],key=len)),len(max(df[self.labels[1]],key=len)))\n",
        "        x=2\n",
        "        while x<max_length:x=x*2\n",
        "        return x\n",
        "            \n",
        "        # self.df=df\n",
        "        # self.tokenizer=tokenizer\n",
        "        # self.max_length=max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_sample=LanguageDataset(df,tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<__main__.LanguageDataset at 0x71f5180f0350>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_size=int(0.8*len(data_sample))\n",
        "val_size=len(data_sample)-train_size\n",
        "train_data,val_data=random_split(data_sample,[train_size,val_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "#load train data\n",
        "train_loader=DataLoader(train_data,batch_size=BATCH_SIZE,shuffle=True)\n",
        "val_loader=DataLoader(val_data,batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_epochs=8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size=BATCH_SIZE\n",
        "model_name='distilgpt2'\n",
        "gpu=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion=nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
        "optimizer=optim.AdamW(model.parameters(),lr=5e-4)\n",
        "tokenizer.pad_token=tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "results=pd.DataFrame(columns=['epoch','transformer','batch_size','gpu','training_loss','validation_loss','epoch_duration_sec'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training epoch 1/8 Batch size: 8,Transformer:distilgpt2: 100%|██████████| 40/40 [00:03<00:00, 13.16it/s, Training Loss=0.574]\n",
            "Validating epoch 1/8 : 100%|██████████| 10/10 [00:00<00:00, 52.38it/s, Validation loss=0.683]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1, Validation Loss:0.6035404801368713\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training epoch 2/8 Batch size: 8,Transformer:distilgpt2: 100%|██████████| 40/40 [00:02<00:00, 14.02it/s, Training Loss=0.666]\n",
            "Validating epoch 2/8 : 100%|██████████| 10/10 [00:00<00:00, 53.31it/s, Validation loss=0.724]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:2, Validation Loss:0.6212345957756042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training epoch 3/8 Batch size: 8,Transformer:distilgpt2: 100%|██████████| 40/40 [00:02<00:00, 13.89it/s, Training Loss=0.446]\n",
            "Validating epoch 3/8 : 100%|██████████| 10/10 [00:00<00:00, 50.87it/s, Validation loss=0.772]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:3, Validation Loss:0.6530129313468933\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training epoch 4/8 Batch size: 8,Transformer:distilgpt2: 100%|██████████| 40/40 [00:02<00:00, 13.77it/s, Training Loss=0.25] \n",
            "Validating epoch 4/8 : 100%|██████████| 10/10 [00:00<00:00, 53.75it/s, Validation loss=0.798]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:4, Validation Loss:0.6834658980369568\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training epoch 5/8 Batch size: 8,Transformer:distilgpt2: 100%|██████████| 40/40 [00:02<00:00, 13.84it/s, Training Loss=0.181]\n",
            "Validating epoch 5/8 : 100%|██████████| 10/10 [00:00<00:00, 51.28it/s, Validation loss=0.876]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:5, Validation Loss:0.7393359541893005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training epoch 6/8 Batch size: 8,Transformer:distilgpt2: 100%|██████████| 40/40 [00:02<00:00, 13.63it/s, Training Loss=0.2]   \n",
            "Validating epoch 6/8 : 100%|██████████| 10/10 [00:00<00:00, 51.03it/s, Validation loss=0.885]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:6, Validation Loss:0.7815186977386475\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training epoch 7/8 Batch size: 8,Transformer:distilgpt2: 100%|██████████| 40/40 [00:02<00:00, 13.63it/s, Training Loss=0.129] \n",
            "Validating epoch 7/8 : 100%|██████████| 10/10 [00:00<00:00, 51.85it/s, Validation loss=0.928]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:7, Validation Loss:0.8004545569419861\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training epoch 8/8 Batch size: 8,Transformer:distilgpt2: 100%|██████████| 40/40 [00:02<00:00, 13.43it/s, Training Loss=0.115] \n",
            "Validating epoch 8/8 : 100%|██████████| 10/10 [00:00<00:00, 52.90it/s, Validation loss=0.983]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:8, Validation Loss:0.840096652507782\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#train loop\n",
        "for epoch in range(num_epochs):\n",
        "    start_time=time.time()\n",
        "    model.train()\n",
        "    epoch_training_loss=0\n",
        "    train_iterator=tqdm(train_loader,desc=f\"Training epoch {epoch+1}/{num_epochs} Batch size: {batch_size},Transformer:{model_name}\")\n",
        "    for batch in train_iterator:\n",
        "       optimizer.zero_grad()\n",
        "       inputs=batch['input_ids'].squeeze(1).to(device)\n",
        "       targets=inputs.clone()\n",
        "       outputs=model(input_ids=inputs,labels=targets)\n",
        "       loss=outputs.loss\n",
        "       loss.backward()\n",
        "       optimizer.step()\n",
        "       train_iterator.set_postfix({'Training Loss':loss.item()})\n",
        "       epoch_training_loss+=loss.item()\n",
        "    #    train_iterator.set_postfix(loss=loss.item())\n",
        "    avg_epoch_training_loss=epoch_training_loss/len(train_iterator)\n",
        "    \n",
        "    #validation\n",
        "    model.eval()\n",
        "    epoch_validation_loss=0\n",
        "    total_loss=0\n",
        "    valid_iterator=tqdm(val_loader,desc=f\"Validating epoch {epoch+1}/{num_epochs} \")\n",
        "    with torch.no_grad():\n",
        "        for batch in valid_iterator:\n",
        "            inputs=batch['input_ids'].squeeze(1).to(device)\n",
        "            targets=inputs.clone()\n",
        "            outputs=model(input_ids=inputs,labels=targets)\n",
        "            loss=outputs.loss\n",
        "            total_loss+=loss\n",
        "            valid_iterator.set_postfix({'Validation loss':loss.item()})\n",
        "            epoch_validation_loss+=loss.item()\n",
        "        avg_epoch_training_loss=epoch_validation_loss/len(valid_iterator)  \n",
        "        \n",
        "        end_time=time.time()\n",
        "        epoch_duration_sec=end_time-start_time\n",
        "        \n",
        "        new_row={\n",
        "            'transformer':model_name,\n",
        "            'batch_size':batch_size,\n",
        "            'gpu':gpu,\n",
        "            'epoch':epoch+1,\n",
        "            'training_loss':avg_epoch_training_loss,\n",
        "            'validation_loss':avg_epoch_training_loss,\n",
        "            }\n",
        "        # results=results.append(new_row,ignore_index=True)\n",
        "        results.loc[len(results)]=new_row\n",
        "        print(f\"Epoch:{epoch+1}, Validation Loss:{total_loss/len(val_loader)}\")\n",
        "          "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Jul  4 15:26:05 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 575.64.01              Driver Version: 576.80         CUDA Version: 12.9     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce RTX 5060 Ti     On  |   00000000:01:00.0  On |                  N/A |\n",
            "|  0%   34C    P8             10W /  180W |    4076MiB /  16311MiB |      4%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A             646      G   /Xwayland                             N/A      |\n",
            "|    0   N/A  N/A          129433      C   /python3.12                           N/A      |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_str=\"Kindney Failure\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_ids=tokenizer.encode(input_str,return_tensors='pt').to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[35854,  1681, 25743]], device='cuda:0')"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        }
      ],
      "source": [
        "output=model.generate(\n",
        "                      input_ids,\n",
        "                      max_length=20,\n",
        "                      num_return_sequences=1,\n",
        "                      do_sample=True,\n",
        "                      top_k=8,\n",
        "                      top_p=0.95,\n",
        "                      temperature=0.5,\n",
        "                      repetition_penalty=1.2,\n",
        "                     \n",
        "                      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[35854,  1681, 25743,   930, 36400,   839, 18922,  5072,    11,   220,\n",
              "         11711, 21545,    11,   220, 18787, 50256]], device='cuda:0')"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "decoded_output=tokenizer.decode(output[0],skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Kindney Failure | Decreased urine output,  fluid retention,  fatigue'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decoded_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model,'SmallDiseaseLM')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#torch.save(model,'drive/My Drive/SmallDiseaseLM.pt')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPrhcaYGQ/D+71wnX07eBuQ",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ai-finetuning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
