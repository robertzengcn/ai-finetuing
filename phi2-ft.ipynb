{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de28676a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (0.16.0)\n",
      "Requirement already satisfied: bitsandbytes in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (0.46.1)\n",
      "Requirement already satisfied: transformers in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (4.53.0)\n",
      "Requirement already satisfied: trl in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (0.19.0)\n",
      "Requirement already satisfied: accelerate in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (1.8.1)\n",
      "Requirement already satisfied: einops in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (0.8.1)\n",
      "Requirement already satisfied: tqdm in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: scipy in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from peft) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from peft) (25.0)\n",
      "Requirement already satisfied: psutil in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from peft) (2.7.1+cu128)\n",
      "Requirement already satisfied: safetensors in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from peft) (0.33.2)\n",
      "Requirement already satisfied: filelock in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from torch>=1.13.0->peft) (4.14.0)\n",
      "Requirement already satisfied: setuptools in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from torch>=1.13.0->peft) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from torch>=1.13.0->peft) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from torch>=1.13.0->peft) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.7.1.26 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from torch>=1.13.0->peft) (9.7.1.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from torch>=1.13.0->peft) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from torch>=1.13.0->peft) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from torch>=1.13.0->peft) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from torch>=1.13.0->peft) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from torch>=1.13.0->peft) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from torch>=1.13.0->peft) (1.13.0.11)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (1.1.5)\n",
      "Requirement already satisfied: datasets>=3.0.0 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from trl) (3.6.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (2.3.0)\n",
      "Requirement already satisfied: xxhash in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.12.13)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install peft bitsandbytes transformers trl accelerate einops tqdm scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50961db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass,field\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60f8a53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robertzeng/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset,load_from_disk\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fb62f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84f81566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de98f1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import interpreter_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc393f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "interpreter_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5be862b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=load_dataset(\"Amod/mental_health_counseling_conversations\",split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56ff0e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Context', 'Response'],\n",
       "    num_rows: 3512\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c84f362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd9db579",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17fc1dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>If everyone thinks you're worthless, then mayb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>Hello, and thank you for your question and see...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Context  \\\n",
       "0  I'm going through some things with my feelings...   \n",
       "1  I'm going through some things with my feelings...   \n",
       "\n",
       "                                            Response  \n",
       "0  If everyone thinks you're worthless, then mayb...  \n",
       "1  Hello, and thank you for your question and see...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85693661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3512, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d91cc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3512 entries, 0 to 3511\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Context   3512 non-null   object\n",
      " 1   Response  3512 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 55.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f42853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_row(row)->str:\n",
    "    question=row['Context']\n",
    "    answer=row['Response']\n",
    "    formatted_string=f\"[INST] {question} [/INST] [RES] {answer} [/RES]\"\n",
    "    return formatted_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad500cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Formatted']=df.apply(format_row,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ff2fcbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [INST] I'm going through some things with my f...\n",
       "1       [INST] I'm going through some things with my f...\n",
       "2       [INST] I'm going through some things with my f...\n",
       "3       [INST] I'm going through some things with my f...\n",
       "4       [INST] I'm going through some things with my f...\n",
       "                              ...                        \n",
       "3507    [INST] My grandson's step-mother sends him to ...\n",
       "3508    [INST] My boyfriend is in recovery from drug a...\n",
       "3509    [INST] The birth mother attempted suicide seve...\n",
       "3510    [INST] I think adult life is making him depres...\n",
       "3511    [INST] I just took a job that requires me to t...\n",
       "Name: Formatted, Length: 3512, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Formatted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6883a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=df.rename(columns={'Formatted':'Text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2b39f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Response</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>If everyone thinks you're worthless, then mayb...</td>\n",
       "      <td>[INST] I'm going through some things with my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>Hello, and thank you for your question and see...</td>\n",
       "      <td>[INST] I'm going through some things with my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>First thing I'd suggest is getting the sleep y...</td>\n",
       "      <td>[INST] I'm going through some things with my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>Therapy is essential for those that are feelin...</td>\n",
       "      <td>[INST] I'm going through some things with my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>I first want to let you know that you are not ...</td>\n",
       "      <td>[INST] I'm going through some things with my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3507</th>\n",
       "      <td>My grandson's step-mother sends him to school ...</td>\n",
       "      <td>Absolutely not! It is never in a child's best ...</td>\n",
       "      <td>[INST] My grandson's step-mother sends him to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3508</th>\n",
       "      <td>My boyfriend is in recovery from drug addictio...</td>\n",
       "      <td>I'm sorry you have tension between you and you...</td>\n",
       "      <td>[INST] My boyfriend is in recovery from drug a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3509</th>\n",
       "      <td>The birth mother attempted suicide several tim...</td>\n",
       "      <td>The true answer is, \"no one can really say wit...</td>\n",
       "      <td>[INST] The birth mother attempted suicide seve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3510</th>\n",
       "      <td>I think adult life is making him depressed and...</td>\n",
       "      <td>How do you help yourself to believe you requir...</td>\n",
       "      <td>[INST] I think adult life is making him depres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3511</th>\n",
       "      <td>I just took a job that requires me to travel f...</td>\n",
       "      <td>hmm this is a tough one!</td>\n",
       "      <td>[INST] I just took a job that requires me to t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3512 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Context  \\\n",
       "0     I'm going through some things with my feelings...   \n",
       "1     I'm going through some things with my feelings...   \n",
       "2     I'm going through some things with my feelings...   \n",
       "3     I'm going through some things with my feelings...   \n",
       "4     I'm going through some things with my feelings...   \n",
       "...                                                 ...   \n",
       "3507  My grandson's step-mother sends him to school ...   \n",
       "3508  My boyfriend is in recovery from drug addictio...   \n",
       "3509  The birth mother attempted suicide several tim...   \n",
       "3510  I think adult life is making him depressed and...   \n",
       "3511  I just took a job that requires me to travel f...   \n",
       "\n",
       "                                               Response  \\\n",
       "0     If everyone thinks you're worthless, then mayb...   \n",
       "1     Hello, and thank you for your question and see...   \n",
       "2     First thing I'd suggest is getting the sleep y...   \n",
       "3     Therapy is essential for those that are feelin...   \n",
       "4     I first want to let you know that you are not ...   \n",
       "...                                                 ...   \n",
       "3507  Absolutely not! It is never in a child's best ...   \n",
       "3508  I'm sorry you have tension between you and you...   \n",
       "3509  The true answer is, \"no one can really say wit...   \n",
       "3510  How do you help yourself to believe you requir...   \n",
       "3511                           hmm this is a tough one!   \n",
       "\n",
       "                                                   Text  \n",
       "0     [INST] I'm going through some things with my f...  \n",
       "1     [INST] I'm going through some things with my f...  \n",
       "2     [INST] I'm going through some things with my f...  \n",
       "3     [INST] I'm going through some things with my f...  \n",
       "4     [INST] I'm going through some things with my f...  \n",
       "...                                                 ...  \n",
       "3507  [INST] My grandson's step-mother sends him to ...  \n",
       "3508  [INST] My boyfriend is in recovery from drug a...  \n",
       "3509  [INST] The birth mother attempted suicide seve...  \n",
       "3510  [INST] I think adult life is making him depres...  \n",
       "3511  [INST] I just took a job that requires me to t...  \n",
       "\n",
       "[3512 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d50c8022",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=new_df[['Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4baa4ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[INST] I'm going through some things with my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[INST] I'm going through some things with my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[INST] I'm going through some things with my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[INST] I'm going through some things with my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[INST] I'm going through some things with my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3507</th>\n",
       "      <td>[INST] My grandson's step-mother sends him to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3508</th>\n",
       "      <td>[INST] My boyfriend is in recovery from drug a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3509</th>\n",
       "      <td>[INST] The birth mother attempted suicide seve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3510</th>\n",
       "      <td>[INST] I think adult life is making him depres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3511</th>\n",
       "      <td>[INST] I just took a job that requires me to t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3512 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text\n",
       "0     [INST] I'm going through some things with my f...\n",
       "1     [INST] I'm going through some things with my f...\n",
       "2     [INST] I'm going through some things with my f...\n",
       "3     [INST] I'm going through some things with my f...\n",
       "4     [INST] I'm going through some things with my f...\n",
       "...                                                 ...\n",
       "3507  [INST] My grandson's step-mother sends him to ...\n",
       "3508  [INST] My boyfriend is in recovery from drug a...\n",
       "3509  [INST] The birth mother attempted suicide seve...\n",
       "3510  [INST] I think adult life is making him depres...\n",
       "3511  [INST] I just took a job that requires me to t...\n",
       "\n",
       "[3512 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c69c68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[INST] I'm going through some things with my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[INST] I'm going through some things with my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[INST] I'm going through some things with my f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  [INST] I'm going through some things with my f...\n",
       "1  [INST] I'm going through some things with my f...\n",
       "2  [INST] I'm going through some things with my f..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0f8cd40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[INST] I'm going through some things with my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[INST] I'm going through some things with my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[INST] I'm going through some things with my f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  [INST] I'm going through some things with my f...\n",
       "1  [INST] I'm going through some things with my f...\n",
       "2  [INST] I'm going through some things with my f..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8880809",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"formatted_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bc4b09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3512 examples [00:00, 92611.38 examples/s]\n"
     ]
    }
   ],
   "source": [
    "training_dataset=load_dataset(\"csv\",data_files=\"formatted_data.csv\",split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41486e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Text'],\n",
       "    num_rows: 3512\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132d0d80",
   "metadata": {},
   "source": [
    "### Fine Tuning Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c48deae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model=\"microsoft/phi-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5127b3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model=\"phi-2-metal-health\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff7389f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 2 files: 100%|██████████| 2/2 [01:12<00:00, 36.29s/it]\n",
      "PhiModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]\n",
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m model.config.pretraining_tp=\u001b[32m1\u001b[39m\n\u001b[32m     25\u001b[39m model=prepare_model_for_kbit_training(model,use_gradient_checkpointing=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m training_arguments=\u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./mhGPT\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msteps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpaged_adamw_8bit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr_scheduler_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcosine\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwarmup_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_step\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     41\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m peft_config=LoraConfig(\n\u001b[32m     44\u001b[39m     r=\u001b[32m32\u001b[39m,\n\u001b[32m     45\u001b[39m     lora_alpha=\u001b[32m64\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     49\u001b[39m     target_modules=[\u001b[33m\"\u001b[39m\u001b[33mWqkv\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mfc1\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mfc2\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     50\u001b[39m )\n\u001b[32m     52\u001b[39m trainer=SFTTrainer(\n\u001b[32m     53\u001b[39m     model=model,\n\u001b[32m     54\u001b[39m     train_dataset=training_dataset,\n\u001b[32m   (...)\u001b[39m\u001b[32m     62\u001b[39m     \u001b[38;5;66;03m# data_collator=None\u001b[39;00m\n\u001b[32m     63\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"
     ]
    }
   ],
   "source": [
    "tokenizer=AutoTokenizer.from_pretrained(base_model,use_fast=True)\n",
    "tokenizer.pad_token=tokenizer.eos_token\n",
    "tokenizer.padding_side=\"right\"\n",
    "\n",
    "bnb_config=BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4but_use_double_quant=False\n",
    ")\n",
    "\n",
    "model=AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True,\n",
    "    flash_attn=True,\n",
    "    flash_rotary=True,\n",
    "    fused_dense=True,\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map=\"auto\",\n",
    "    revision=\"refs/pr/23\"\n",
    ")\n",
    "model.config.use_cache=False\n",
    "model.config.pretraining_tp=1\n",
    "model=prepare_model_for_kbit_training(model,use_gradient_checkpointing=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62ee1d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments=TrainingArguments(\n",
    "    output_dir=\"./mhGPT\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=32,\n",
    "    # evaluation_strategy=\"steps\",\n",
    "    # eval_steps=1000,\n",
    "    logging_steps=15,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    learning_rate=2e-4,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    save_steps=1500,\n",
    "    warmup_ratio=0.05,\n",
    "    weight_decay=0.01,\n",
    "    # max_step=-1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bdd73b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config=LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"Wqkv\",\"fc1\",\"fc2\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14ef4528",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding EOS to train dataset: 100%|██████████| 3512/3512 [00:00<00:00, 72315.94 examples/s]\n",
      "Tokenizing train dataset:   0%|          | 0/3512 [00:00<?, ? examples/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m trainer=\u001b[43mSFTTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# train_dataset_text_field=\"Text\",\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# max_seq_length=690,\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# tokenizer=tokenizer,\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_arguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# tokenizer=tokenizer,\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# packing=False,\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# data_collator=None\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:473\u001b[39m, in \u001b[36mSFTTrainer.__init__\u001b[39m\u001b[34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics, peft_config, formatting_func)\u001b[39m\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.completion_only_loss \u001b[38;5;129;01mand\u001b[39;00m formatting_func:\n\u001b[32m    467\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    468\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA formatting function was provided while `completion_only_loss=True`, which is incompatible. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    469\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUsing a formatter converts the dataset to a language modeling type, conflicting with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    470\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcompletion-only loss. To resolve this, apply your formatting function before passing the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    471\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdataset, or disable `completion_only_loss` in `SFTConfig`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    472\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m train_dataset = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessing_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpacking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatting_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    475\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m eval_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    477\u001b[39m     packing = args.packing \u001b[38;5;28;01mif\u001b[39;00m args.eval_packing \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m args.eval_packing\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:770\u001b[39m, in \u001b[36mSFTTrainer._prepare_dataset\u001b[39m\u001b[34m(self, dataset, processing_class, args, packing, formatting_func, dataset_name)\u001b[39m\n\u001b[32m    767\u001b[39m                 processed = {\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m: processing_class(text=example[dataset_text_field]).input_ids}\n\u001b[32m    768\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m processed\n\u001b[32m--> \u001b[39m\u001b[32m770\u001b[39m     dataset = \u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    771\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    772\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    773\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprocessing_class\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessing_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    774\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdataset_text_field\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset_text_field\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    775\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43massistant_only_loss\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43massistant_only_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmap_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[38;5;66;03m# Pack or truncate\u001b[39;00m\n\u001b[32m    781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m packing:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages/datasets/arrow_dataset.py:557\u001b[39m, in \u001b[36mtransmit_format.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    550\u001b[39m self_format = {\n\u001b[32m    551\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_type,\n\u001b[32m    552\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mformat_kwargs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_kwargs,\n\u001b[32m    553\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_columns,\n\u001b[32m    554\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33moutput_all_columns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._output_all_columns,\n\u001b[32m    555\u001b[39m }\n\u001b[32m    556\u001b[39m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m out: Union[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDatasetDict\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    558\u001b[39m datasets: \u001b[38;5;28mlist\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlist\u001b[39m(out.values()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[32m    559\u001b[39m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages/datasets/arrow_dataset.py:3079\u001b[39m, in \u001b[36mDataset.map\u001b[39m\u001b[34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc, try_original_type)\u001b[39m\n\u001b[32m   3073\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3074\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[32m   3075\u001b[39m         unit=\u001b[33m\"\u001b[39m\u001b[33m examples\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   3076\u001b[39m         total=pbar_total,\n\u001b[32m   3077\u001b[39m         desc=desc \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mMap\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   3078\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[32m-> \u001b[39m\u001b[32m3079\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m                \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages/datasets/arrow_dataset.py:3501\u001b[39m, in \u001b[36mDataset._map_single\u001b[39m\u001b[34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, try_original_type)\u001b[39m\n\u001b[32m   3499\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m batched:\n\u001b[32m   3500\u001b[39m     _time = time.time()\n\u001b[32m-> \u001b[39m\u001b[32m3501\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miter_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_iterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3502\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mupdate_data\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3503\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages/datasets/arrow_dataset.py:3475\u001b[39m, in \u001b[36mDataset._map_single.<locals>.iter_outputs\u001b[39m\u001b[34m(shard_iterable)\u001b[39m\n\u001b[32m   3473\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3474\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[32m-> \u001b[39m\u001b[32m3475\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m i, \u001b[43mapply_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages/datasets/arrow_dataset.py:3398\u001b[39m, in \u001b[36mDataset._map_single.<locals>.apply_function\u001b[39m\u001b[34m(pa_inputs, indices, offset)\u001b[39m\n\u001b[32m   3396\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Utility to apply the function on a selection of columns.\"\"\"\u001b[39;00m\n\u001b[32m   3397\u001b[39m inputs, fn_args, additional_args, fn_kwargs = prepare_inputs(pa_inputs, indices, offset=offset)\n\u001b[32m-> \u001b[39m\u001b[32m3398\u001b[39m processed_inputs = \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3399\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m prepare_outputs(pa_inputs, inputs, processed_inputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ai-finetuning/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:767\u001b[39m, in \u001b[36mSFTTrainer._prepare_dataset.<locals>.tokenize\u001b[39m\u001b[34m(example, processing_class, dataset_text_field, assistant_only_loss)\u001b[39m\n\u001b[32m    765\u001b[39m         processed = {k: processed[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33massistant_masks\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m processed}\n\u001b[32m    766\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m767\u001b[39m         processed = {\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m: processing_class(text=\u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_text_field\u001b[49m\u001b[43m]\u001b[49m).input_ids}\n\u001b[32m    768\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m processed\n",
      "\u001b[31mKeyError\u001b[39m: 'text'"
     ]
    }
   ],
   "source": [
    "trainer=SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=training_dataset,\n",
    "    peft_config=peft_config,\n",
    "    # train_dataset_text_field=\"Text\",\n",
    "    # max_seq_length=690,\n",
    "    # tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    # tokenizer=tokenizer,\n",
    "    # packing=False,\n",
    "    # data_collator=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca72d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeb8105",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-finetuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
